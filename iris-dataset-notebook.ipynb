{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using Tensorflow to create model\n",
    "\n",
    "Problem: Use Tensorflow to create a model to predict the species of Iris from a flowerâ€™s sepal width, sepal length, petal width, and petal length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the data\n",
    "\n",
    "First we read the data from csv file and format it in a suitable manner so we can interact with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reading data from csv file using pandas\n",
    "iris_data = pd.read_csv('data/iris-data-set.csv')\n",
    "# Use pandas get_dummies to convert species column values into One Hot Encoding\n",
    "data_set = pd.get_dummies(iris_data, columns=['species'])\n",
    "\n",
    "# Separate data set into input (Iris values)  and output (Iris species)\n",
    "input = data_set[data_set.columns.values[0:-3]]\n",
    "input = np.array(input)\n",
    "\n",
    "output = data_set[data_set.columns.values[-3:]]\n",
    "output = np.array(output, dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "We create the model we are going to use to train and then run the tests on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializing placeholders\n",
    "x_inputs = tf.placeholder(shape=[None, 4], dtype=tf.float32)\n",
    "y_outputs = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "\n",
    "# Creating variables for neurons\n",
    "# In order to achieve better results we will create two layers with 8 neurons each\n",
    "\n",
    "# First Layer \n",
    "w1 = tf.Variable(tf.random_normal(shape=[4,8]))\n",
    "b1 = tf.Variable(tf.random_normal(shape=[8]))   # First Bias\n",
    "\n",
    "# Second Layer\n",
    "w2 = tf.Variable(tf.random_normal(shape=[8,3])) \n",
    "b2 = tf.Variable(tf.random_normal(shape=[3]))\n",
    "\n",
    "# We add the operation nodes\n",
    "# For the first layer\n",
    "first_layer_output = tf.nn.relu(tf.add(tf.matmul(x_inputs, w1), b1))\n",
    "# for the secon layer taking the outputs of the first layer\n",
    "final_layer_output = tf.nn.softmax(tf.add(tf.matmul(first_layer_output, w2), b2))\n",
    "\n",
    "\n",
    "# Cost Function\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_outputs * tf.log(final_layer_output), axis=0))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data into training and testing\n",
    "\n",
    "Problem: Split the data set into a training set and a testing set. You should investigate the best way to do this, and list any online references used in your notebook. If you wish to, you can write some code to randomly separate the data on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data using sklearn's train_test_split function. Setting the test size to 1/4 of the todal set size.\n",
    "# random_state seed set to 42.\n",
    "X_train, X_test, y_train, y_test = train_test_split(input, output, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model\n",
    "Problem: Use the testing set to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "...End of Training.\n"
     ]
    }
   ],
   "source": [
    "# Initializing variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "print('Training the model...')\n",
    "for i in range(0, 2000):\n",
    "    sess.run(optimizer, feed_dict={x_inputs: X_train, y_outputs: y_train})\n",
    "    # Calculate loss every 50 iterations\n",
    "    # if i % 50 == 0:\n",
    "    #    print('Iteration', i, '|', 'Loss:', sess.run(loss, feed_dict={x_inputs: X_train, y_outputs: y_train}))\n",
    "print('...End of Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model\n",
    "Problem: Use the testing set to test your model, clearly calculating and displaying the error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: vesicolor Predicted: virginica\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: virginica Predicted: vesicolor\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: setosa Predicted: setosa\n",
      "Actual: virginica Predicted: virginica\n",
      "Actual: vesicolor Predicted: vesicolor\n",
      "Actual: setosa Predicted: setosa\n",
      "Error rate: 0.975814\n"
     ]
    }
   ],
   "source": [
    "# Small function to improve readability (since species are separated into one hot encoding)\n",
    "# getIrisSpecies(species) returns the name of the iris sub specie depending on the \n",
    "def getIrisSpecies(species):\n",
    "    species = species.transpose()\n",
    "    if (species[0] == 1):\n",
    "        return \"setosa\"\n",
    "    elif (species[1] == 1):\n",
    "        return \"vesicolor\"\n",
    "    elif (species[2] == 1):\n",
    "        return \"virginica\"\n",
    "\n",
    "# Run model on test set\n",
    "for i in range(len(X_test)):\n",
    "    print('Actual:', getIrisSpecies(y_test[i]), 'Predicted:', getIrisSpecies(np.rint(sess.run(final_layer_output, feed_dict={x_inputs: [X_test[i]]}))))\n",
    "\n",
    "# Print error rate.\n",
    "print('Error rate:', sess.run(loss, feed_dict={x_inputs: X_test, y_outputs: y_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
